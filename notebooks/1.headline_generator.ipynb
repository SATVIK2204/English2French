{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pickle import dump,load\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import tqdm\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/raw/english2french.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>french</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145432</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>145433</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>145434</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>145435</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>145436</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>145437 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                  english  \\\n0                                                     Go.   \n1                                                    Run!   \n2                                                    Run!   \n3                                                    Wow!   \n4                                                   Fire!   \n...                                                   ...   \n145432  A carbon footprint is the amount of carbon dio...   \n145433  Death is something that we're often discourage...   \n145434  Since there are usually multiple websites on a...   \n145435  If someone who doesn't know your background sa...   \n145436  It may be impossible to get a completely error...   \n\n                                                   french  \n0                                                    Va !  \n1                                                 Cours !  \n2                                                Courez !  \n3                                              Ça alors !  \n4                                                Au feu !  \n...                                                   ...  \n145432  Une empreinte carbone est la somme de pollutio...  \n145433  La mort est une chose qu'on nous décourage sou...  \n145434  Puisqu'il y a de multiples sites web sur chaqu...  \n145435  Si quelqu'un qui ne connaît pas vos antécédent...  \n145436  Il est peut-être impossible d'obtenir un Corpu...  \n\n[145437 rows x 2 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any null present in data\r\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting columns to lists before cleaning\r\n",
    "english=df['english'].to_list()\r\n",
    "french=df['french'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import our DfCleaner module\r\n",
    "%autoreload 2\r\n",
    "from headline_generator.src.preprocessing.cleaning import DfCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner=DfCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 examples cleaned out of 145437\n",
      "20000 examples cleaned out of 145437\n",
      "30000 examples cleaned out of 145437\n",
      "40000 examples cleaned out of 145437\n",
      "50000 examples cleaned out of 145437\n",
      "60000 examples cleaned out of 145437\n",
      "70000 examples cleaned out of 145437\n",
      "80000 examples cleaned out of 145437\n",
      "90000 examples cleaned out of 145437\n",
      "100000 examples cleaned out of 145437\n",
      "110000 examples cleaned out of 145437\n",
      "120000 examples cleaned out of 145437\n",
      "130000 examples cleaned out of 145437\n",
      "140000 examples cleaned out of 145437\n",
      "Cleaning Done\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the articles\r\n",
    "cleaned_english=cleaner.clean(english,stem=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 examples cleaned out of 145437\n",
      "20000 examples cleaned out of 145437\n",
      "30000 examples cleaned out of 145437\n",
      "40000 examples cleaned out of 145437\n",
      "50000 examples cleaned out of 145437\n",
      "60000 examples cleaned out of 145437\n",
      "70000 examples cleaned out of 145437\n",
      "80000 examples cleaned out of 145437\n",
      "90000 examples cleaned out of 145437\n",
      "100000 examples cleaned out of 145437\n",
      "110000 examples cleaned out of 145437\n",
      "120000 examples cleaned out of 145437\n",
      "130000 examples cleaned out of 145437\n",
      "140000 examples cleaned out of 145437\n",
      "Cleaning Done\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the headline\r\n",
    "cleaned_french=cleaner.clean(french,stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=cleaned_english\r\n",
    "df2=cleaned_french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 examples cleaned out of 145437\n",
      "20000 examples cleaned out of 145437\n",
      "30000 examples cleaned out of 145437\n",
      "40000 examples cleaned out of 145437\n",
      "50000 examples cleaned out of 145437\n",
      "60000 examples cleaned out of 145437\n",
      "70000 examples cleaned out of 145437\n",
      "80000 examples cleaned out of 145437\n",
      "90000 examples cleaned out of 145437\n",
      "100000 examples cleaned out of 145437\n",
      "110000 examples cleaned out of 145437\n",
      "120000 examples cleaned out of 145437\n",
      "130000 examples cleaned out of 145437\n",
      "140000 examples cleaned out of 145437\n",
      "Cleaning Done\n",
      "10000 examples cleaned out of 145437\n",
      "20000 examples cleaned out of 145437\n",
      "30000 examples cleaned out of 145437\n",
      "40000 examples cleaned out of 145437\n",
      "50000 examples cleaned out of 145437\n",
      "60000 examples cleaned out of 145437\n",
      "70000 examples cleaned out of 145437\n",
      "80000 examples cleaned out of 145437\n",
      "90000 examples cleaned out of 145437\n",
      "100000 examples cleaned out of 145437\n",
      "110000 examples cleaned out of 145437\n",
      "120000 examples cleaned out of 145437\n",
      "130000 examples cleaned out of 145437\n",
      "140000 examples cleaned out of 145437\n",
      "Cleaning Done\n",
      "Wall time: 34min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "# Remove frequent and rare words (This might take some time to run)\r\n",
    "cleaned_english =cleaner.remove_frequent_rare(cleaned_english,frequent=True,rare=True)\r\n",
    "cleaned_french =cleaner.remove_frequent_rare(cleaned_french,frequent=True,rare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might have empty strings in our data right now so lets remove them by making a dataframe and replace empty string\r\n",
    "# with NaN and then using the dropna() function\r\n",
    "\r\n",
    "df_temp=pd.DataFrame(list(zip(cleaned_english,cleaned_french)),columns=['english','french'])\r\n",
    "df_temp['english'].replace('',np.nan,inplace=True)\r\n",
    "df_temp['french'].replace('',np.nan,inplace=True)\r\n",
    "df_temp.dropna(inplace=True)\r\n",
    "\r\n",
    "cleaned_english=df['english'].tolist()\r\n",
    "cleaned_french=df['french'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the interm data to reuse it and not have to run the above code again\r\n",
    "dump(cleaned_english, open('../data/interim/cleaned_english.pkl', 'wb'))\r\n",
    "dump(cleaned_french, open('../data/interim/cleaned_french.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (from now on we will load this data and use it further)\r\n",
    "cleaned_english=load(open('../data/interim/cleaned_english.pkl', 'rb'))\r\n",
    "cleaned_french=load(open('../data/interim/cleaned_french.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframe\r\n",
    "data=pd.DataFrame(list(zip(cleaned_english,cleaned_french)),columns=['english','french'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>french</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  english      french\n0     Go.        Va !\n1    Run!     Cours !\n2    Run!    Courez !\n3    Wow!  Ça alors !\n4   Fire!    Au feu !"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from headline_generator.src.preprocessing.preprocess import PrepareTheData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Done\n",
      "Replacing Done\n",
      "token2idx created\n",
      "Added Start and End tokens\n",
      "tokens_to_indices created\n",
      "Presprocessing done\n"
     ]
    }
   ],
   "source": [
    "dataset=PrepareTheData(data,max_vocab=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "145437"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of examples in our final dataset\r\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.999 * len(dataset))\r\n",
    "test_size = len(dataset) - train_size\r\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clear any cache memory\r\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can run this code to see the pytorch memory usage, this can be useful to display periodically during training, or when handling out-of-memory exceptions.\r\n",
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# define the device to work on\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def collate(batch):\r\n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\r\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\r\n",
    "    \r\n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\r\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\r\n",
    "    padded_targets = pad_sequence(targets, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\r\n",
    "    \r\n",
    "    # Sort by length for CUDA optimizations\r\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\r\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\r\n",
    "\r\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\r\n",
    "\r\n",
    "\r\n",
    "batch_size = 256\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate)\r\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from headline_generator.src.models.encoder_decoder import EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bace998e984be3aec4624021ad1fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  1\ttrain_loss: 4.14e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ce813b4ce540ca8c24bac4ef78ee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  2\ttrain_loss: 2.42e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64c71268ea4fa0ad513fde97d75b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  3\ttrain_loss: 1.90e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09e080b72a64546b79f525772531a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  4\ttrain_loss: 1.68e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932184c83e4f465fbf072059e4837362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  5\ttrain_loss: 1.55e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9375a14e2654dc2854e076336255f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  6\ttrain_loss: 1.45e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca45fcf763a840779aaffd9a01deccb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  7\ttrain_loss: 1.38e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f034d0b4815a4cf9808a854fd4f170cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  8\ttrain_loss: 1.32e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a93ae1dd99843e095bd48dfb4c83050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  9\ttrain_loss: 1.27e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c8481310fa427394da455832ccc405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training:   0%|          | 0/568 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 10\ttrain_loss: 1.23e-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(\r\n",
    "    inputs_vocab_size=len(dataset.token2idx_inputs),\r\n",
    "    targets_vocab_size=len(dataset.token2idx_targets),\r\n",
    "    hidden_size=256,\r\n",
    "    embedding_dim=100, \r\n",
    "    batch_size=batch_size, \r\n",
    "    targets_start_idx=dataset.token2idx_targets[dataset.start_of_sequence_token],\r\n",
    "    targets_stop_idx=dataset.token2idx_targets[dataset.end_of_sequence_token],\r\n",
    ").to(device)\r\n",
    "\r\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)\r\n",
    "\r\n",
    "# Training loop\r\n",
    "model.train()\r\n",
    "for epoch in range(10):\r\n",
    "    total_loss = total = 0\r\n",
    "    progress_bar = tqdm.tqdm_notebook(train_loader, desc='Training', leave=False,total=len(train_dataloader))\r\n",
    "    for inputs, targets, lengths in progress_bar:\r\n",
    "        # Clean old gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # Forwards pass\r\n",
    "        loss = model(inputs, targets, lengths)\r\n",
    "\r\n",
    "        # Perform gradient descent, backwards pass\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        # Take a step in the right direction\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # Record metrics\r\n",
    "        total_loss += loss.item()\r\n",
    "        total += targets.size(1)\r\n",
    "\r\n",
    "    train_loss = total_loss / total\r\n",
    "    tqdm.write(f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.2e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> it s been a while hasn t it\n",
      "cela fait un peu de papier ne l on donc nous sommes pas\n",
      "\n",
      "> which  are you \n",
      "quelle  d  tu \n",
      "\n",
      "> tom is a good \n",
      "tom est un bon \n",
      "\n",
      "> he went out of the room without being  by anyone\n",
      "il est allé dans la pièce sans lire ne  personne\n",
      "\n",
      "> there s still so much left to do\n",
      "il beaucoup encore pour faire\n",
      "\n",
      "> i don t have enough \n",
      "je n ai pas assez d une vie\n",
      "\n",
      "> what do you plan to do\n",
      "que tu t  à faire\n",
      "\n",
      "> that s your half\n",
      "c est votre photo\n",
      "\n",
      "> if you act like a child you will be  as such\n",
      "si tu te prie comme un enfant tu seras du petit\n",
      "\n",
      "> i felt sorry for you\n",
      "je  être à votre part\n",
      "\n",
      "> i  we change clothes first\n",
      "je n ai  que nous  dimanche à premier premier\n",
      "\n",
      "> i hate it here\n",
      "je déteste ça\n",
      "\n",
      "> she didn t want him to play \n",
      "elle n a pas voulu qu il joue au lit\n",
      "\n",
      "> can you take a little break\n",
      "est ce que tu  prendre une \n",
      "\n",
      "> i have some  in my left hand\n",
      "je prends des  dans ma main \n",
      "\n",
      "> tom is  ever on time\n",
      "tom  jamais sur le temps\n",
      "\n",
      "> you can smoke in this room\n",
      "vous pouvez fumer dans cinq jours\n",
      "\n",
      "> i let the cat out of the house\n",
      "je porte le chat hors de la maison\n",
      "\n",
      "> she  him of his mother\n",
      "elle lui  de sa mère\n",
      "\n",
      "> what does this stand for\n",
      "que  cette place\n",
      "\n",
      "> there are a couple of \n",
      "il y a  des \n",
      "\n",
      "> he has a \n",
      "il est un \n",
      "\n",
      "> i have the dictionary\n",
      "j ai le dictionnaire\n",
      "\n",
      "> i just had a talk with your doctor\n",
      "je viens de faire avec un \n",
      "\n",
      "> i heard a noise\n",
      "j  une enfant\n",
      "\n",
      "> let me see it\n",
      "laisse moi parler\n",
      "\n",
      "> her blue shoes go well with that dress\n",
      "son   tous les cours avec cette robe\n",
      "\n",
      "> don t worry about that\n",
      "ne te fais pas sur ça\n",
      "\n",
      "> he  having written to me\n",
      "il ne doit avoir bien payé\n",
      "\n",
      "> we re staying\n",
      "nous \n",
      "\n",
      "> i am tired of listening to his long speech\n",
      "je suis fatigué de mieux de le discours pendant son discours\n",
      "\n",
      "> i ve done this before\n",
      "j ai fait ça auparavant\n",
      "\n",
      "> have you ever  a \n",
      "as tu jamais  à main\n",
      "\n",
      "> tom put on his \n",
      "tom  son  à l \n",
      "\n",
      "> i had a  experience\n",
      "j étais  de \n",
      "\n",
      "> you can t have the job\n",
      "tu ne peux pas aies le boulot du travail\n",
      "\n",
      "> the  of the  was  by the  party\n",
      "les  de la  était  par le  par la \n",
      "\n",
      "> a lot of people swim here in the summer\n",
      "beaucoup de gens qui  ici dans l été l été là\n",
      "\n",
      "> he  it\n",
      "il le \n",
      "\n",
      "> let me help you\n",
      "laissez moi vous aider\n",
      "\n",
      "> let s  we are \n",
      "nous faisons trop \n",
      "\n",
      "> she got out of the car\n",
      "elle est  à la voiture\n",
      "\n",
      "> the teacher told them to stop \n",
      "le crois que je ne t arrêter de \n",
      "\n",
      "> the  was \n",
      "le  fut \n",
      "\n",
      "> she  in \n",
      "elle joue avec la revoir\n",
      "\n",
      "> i hate  like him\n",
      "je déteste l aime\n",
      "\n",
      "> stop reading\n",
      " rester à boire\n",
      "\n",
      "> the message was \n",
      "ce fut \n",
      "\n",
      "> keep your  clean\n",
      "garde le sous montre\n",
      "\n",
      "> can you send the  up\n",
      "on t  l \n",
      "\n",
      "> he s in good  \n",
      "il est bien du  \n",
      "\n",
      "> it s finally my turn\n",
      "ça fait  mon tour\n",
      "\n",
      "> i m right  you\n",
      "je ne  autant de prendre\n",
      "\n",
      "> he   of all the students\n",
      "il porte aucun  de toutes les \n",
      "\n",
      "> i got to know her through one of my friends\n",
      "je l ai rendu par sa peur de mes amis\n",
      "\n",
      "> maybe we should talk about this first\n",
      "peut être devrions nous parler ça à ce matin\n",
      "\n",
      "> let me do the talking\n",
      "laissez moi le parler\n",
      "\n",
      "> we are  with a  of problems\n",
      "nous nous  un  problèmes\n",
      "\n",
      "> that dress  her \n",
      "cette robe de  au \n",
      "\n",
      "> may i go\n",
      "je voudrais y aller\n",
      "\n",
      "> she had a strange hat on\n",
      "elle eut un étrange chapeau\n",
      "\n",
      "> we all want the same thing\n",
      "nous voulons tous la même chose\n",
      "\n",
      "> i ve got a  of \n",
      "j ai  mal de \n",
      "\n",
      "> we want tom to sing with us\n",
      "nous voulons que tom  avec nous\n",
      "\n",
      "> i want you to be prepared\n",
      "je veux que vous soyez prête\n",
      "\n",
      "> i made a couple \n",
      "je pris quelques \n",
      "\n",
      "> i tried but i did not succeed\n",
      "j ai  mais je n avoir encore \n",
      "\n",
      "> don t you feel anything\n",
      "ne parlez vous\n",
      "\n",
      "> no  have been  against the \n",
      "aucun  n a jamais été contre le \n",
      "\n",
      "> i hope you have  enough to see the difference\n",
      "j espère que tu  assez à  le \n",
      "\n",
      "> tom has passed away\n",
      "tom est mort\n",
      "\n",
      "> the  lock \n",
      "les filles  au \n",
      "\n",
      "> we re going to do everything we can\n",
      "nous allons faire tout ce que nous pouvons\n",
      "\n",
      "> don t worry there s nothing wrong with you\n",
      "ne t en faites pas là ne rien à toi à vous\n",
      "\n",
      "> i don t remember you asking me to do that\n",
      "je ne me souviens rien que vous m aimez m faire cela\n",
      "\n",
      "> i had two  of the book\n",
      "j ai bien  à l \n",
      "\n",
      "> i had too much to drink last night\n",
      "j ai trop bu hier soir\n",
      "\n",
      "> i ll be free\n",
      "je serai libre\n",
      "\n",
      "> could you show me this bag\n",
      "pourrais tu me montrer le \n",
      "\n",
      "> what is going on\n",
      "que va t il\n",
      "\n",
      "> i think we re too young\n",
      "je pense que nous sommes trop jeunes\n",
      "\n",
      "> have you met the \n",
      "avez vous jamais l dont mes \n",
      "\n",
      "> i am going to leave my present job\n",
      "je vais quitter mon cadeau à perdre\n",
      "\n",
      "> i think we d better do what tom \n",
      "je pense que nous  mieux de  tom que tom est tom\n",
      "\n",
      "> do you take me for a  \n",
      "que me prendre un  \n",
      "\n",
      "> i almost caught the \n",
      "je  la classe\n",
      "\n",
      "> i will go if you go\n",
      "je vais si maintenant te rendre\n",
      "\n",
      "> put your  in the safe\n",
      " tes  en sécurité\n",
      "\n",
      "> are you american\n",
      "êtes vous \n",
      "\n",
      "> i m going to explain all this in more  later\n",
      "je vais parler ça tout ce  plus tard\n",
      "\n",
      "> has your dog ever  you\n",
      "votre chien t il jamais les \n",
      "\n",
      "> i won t let you die\n",
      "je ne t  pas mourir\n",
      "\n",
      "> i ve been trying to get a little  every day\n",
      "j essaie d  un peu plus chaque jour\n",
      "\n",
      "> she quickly opened the letter\n",
      "elle  la lettre\n",
      "\n",
      "> that s your answer for everything isn t it\n",
      "c est ta réponse pour tout ceci n est ce pas\n",
      "\n",
      "> does this look  to you\n",
      "cela te semble t il \n",
      "\n",
      "> i d like a hotel \n",
      "j aimerais l hôtel d hôtel\n",
      "\n",
      "> i have no \n",
      "je n ai aucune \n",
      "\n",
      "> you are  too much of her\n",
      "à quelle  trop d elle\n",
      "\n",
      "> we know so little about tom\n",
      "on sait tellement de tom\n",
      "\n",
      "> i got \n",
      "j ai pris un \n",
      "\n",
      "> the  is in the \n",
      "les   dans le bois\n",
      "\n",
      "> mary  many  for her birthday\n",
      " d une  de nombreuses  pour son pour son anniversaire\n",
      "\n",
      "> he is a great \n",
      "c est un verre \n",
      "\n",
      "> i came to japan from \n",
      "je suis au japon du \n",
      "\n",
      "> we saw   the  \n",
      "on a presque  en  du \n",
      "\n",
      "> a  was  to set up a  in  of the dead man\n",
      "un  a été  sur le  aux  de la mort de l  d entendre l\n",
      "\n",
      "> it looks like a \n",
      "ça  à une \n",
      "\n",
      "> let me handle it\n",
      "laissez moi  mon \n",
      "\n",
      "> they don t make them like they used to\n",
      "ils ne leur fera pas d eux ils \n",
      "\n",
      "> he likes watching   on tv\n",
      "il aime regarder le plus arrête de la télé\n",
      "\n",
      "> is tom one of your friends\n",
      "tom est il de vos amis\n",
      "\n",
      "> your  is \n",
      "votre  de \n",
      "\n",
      "> tom   his wine\n",
      "tom  la \n",
      "\n",
      "> my father isn t at home\n",
      "mon père n est pas chez le\n",
      "\n",
      "> he left his son a large \n",
      "il est  un  avec un  \n",
      "\n",
      "> make it \n",
      "faites\n",
      "\n",
      "> the woman who he thought was his  was a \n",
      "la femme qui il était  son  fut \n",
      "\n",
      "> i can do this with you or without you\n",
      "je peux le faire de ou non je vous\n",
      "\n",
      "> the  is not open on monday\n",
      "le  n est pas  lundi\n",
      "\n",
      "> at first i  him for your brother\n",
      "je l ai  pour ton frère\n",
      "\n",
      "> you don t have what it takes to be a \n",
      "tu n avez pas  de plus un \n",
      "\n",
      "> can you do this problem\n",
      "peux tu faire ce problème\n",
      "\n",
      "> i will do the shopping for her birthday\n",
      "je ferai le   ans\n",
      "\n",
      "> he could not send his son to school\n",
      "il n  ne  à son fils\n",
      "\n",
      "> he failed the \n",
      "il  des \n",
      "\n",
      "> i m surprised to see you\n",
      "je suis pas surprise de vous voir\n",
      "\n",
      "> i am seeing my uncle tomorrow\n",
      "je suis  mon oncle demain\n",
      "\n",
      "> i can t believe your  let you go\n",
      "je n arrive pas à croire ta  t  vouloir partir\n",
      "\n",
      "> i m having the same problems\n",
      "ça en ai \n",
      "\n",
      "> i thought you d never get here\n",
      "je pensais que vous ne vous jamais  ici\n",
      "\n",
      "> she was  by the accident\n",
      "il le  qui l accident\n",
      "\n",
      "> it s \n",
      "c est \n",
      "\n",
      "> they had no  no hair and no \n",
      "elles ne  aucun  et ne pas de nourriture\n",
      "\n",
      "> if i remember  that s the song tom  at mary s \n",
      "si je me rappelle avoir pris conscience ce que tom passe à marie pour la manière de tom est\n",
      "\n",
      "> tom isn t doing it the right way\n",
      "tom n y  pas le chat chemin\n",
      "\n",
      "> your watch is on the desk\n",
      "ta montre est sur le bureau\n",
      "\n",
      "> he made up his mind to  her\n",
      "il a décidé à lui \n",
      "\n",
      "> i will not do it again\n",
      "je ne le  plus\n",
      "\n",
      "> i don t care how old you are\n",
      "je me  de ses  vous avez vous\n",
      "\n",
      "> you don t seem \n",
      "vous ne  pas d air d un coup d idiot\n",
      "\n",
      "> it s really cold tonight\n",
      "il fait vraiment froid ce soir\n",
      "\n",
      "> come by later i have something for you\n",
      "viens de plus tard que j ai quelque chose\n",
      "\n",
      "> he  me a new job\n",
      "il m a  une nouvelle emploi\n",
      "\n",
      "> we broke up\n",
      "nous l avons \n",
      "\n",
      "> i m  the radio i found on my way home\n",
      "je suis les  du  j ai trouvé à la  de rentrer à la maison à la\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's Predict from our test data\r\n",
    "model.eval()\r\n",
    "total_loss = total = 0\r\n",
    "with torch.no_grad():\r\n",
    "    for inputs, _, lengths in test_loader:\r\n",
    "        print('>', ' '.join([\r\n",
    "            dataset.idx2token_inputs[idx] if dataset.idx2token_inputs[idx]!=\"<UNK>\" else ''\r\n",
    "            for idx in inputs.cpu()[0].numpy()[1:-1]\r\n",
    "        ]))\r\n",
    "\r\n",
    "        # Forwards pass\r\n",
    "        outputs = model.predict(inputs, lengths)\r\n",
    "        print(' '.join([\r\n",
    "            dataset.idx2token_targets[idx] if dataset.idx2token_targets[idx]!=\"<UNK>\" else ''\r\n",
    "            for idx in outputs[:-1]\r\n",
    "        ]))\r\n",
    "        \r\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f3de5096ca57544369bb14db0d707c452af519be01e653fe2c6b8aa83f4de32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python388jvsc74a57bd07f3de5096ca57544369bb14db0d707c452af519be01e653fe2c6b8aa83f4de32"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "7f3de5096ca57544369bb14db0d707c452af519be01e653fe2c6b8aa83f4de32"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}